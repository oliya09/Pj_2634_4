#!/usr/bin/env python3
# rf_model_simple.py
"""
–û–±—É—á–µ–Ω–∏–µ RandomForestClassifier –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö NASA Exoplanet Archive
—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∏ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–∏—à–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import joblib

# === 1Ô∏è‚É£ –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã ===
def find_table_start(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f):
            if line.startswith("pl_name"):
                return i
    return None


csv_file = "test.csv"
start_line = find_table_start(csv_file)
if start_line is None:
    raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã!")
else:
    print(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞—á–∏–Ω–∞—è —Å —Å—Ç—Ä–æ–∫–∏: {start_line}")

# === 2Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ ===
df = pd.read_csv(csv_file, skiprows=start_line)
print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏ {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫.")

# === 3Ô∏è‚É£ –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ ===
feature_columns = [
    "pl_orbper", "pl_rade", "pl_bmasse",
    "pl_eqt", "st_teff", "st_mass", "st_rad"
]
target_column = "default_flag"

df = df[feature_columns + [target_column]].dropna()
print(f"\nüìà –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(df)} —Å—Ç—Ä–æ–∫.")
print(df[target_column].value_counts())

# === 4Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ ===
unique_classes = df[target_column].unique()
if len(unique_classes) < 2:
    print("\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å! –°–æ–∑–¥–∞—ë–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—É—é –º–µ—Ç–∫—É 'target' (—Ä–∞–¥–∏—É—Å + —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ + —à—É–º).")
    median_rade = df["pl_rade"].median()
    median_eqt = df["pl_eqt"].median()
    df["target"] = ((df["pl_rade"] * 0.6 + df["pl_eqt"] * 0.4 +
                     np.random.normal(0, 0.05, len(df))) >
                    (median_rade * 0.6 + median_eqt * 0.4)).astype(int)
    y = df["target"].values
    print(f"üìä –ë–∞–ª–∞–Ω—Å –Ω–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤:\n{pd.Series(y).value_counts()}")
else:
    y = df[target_column].values

X = df[feature_columns].values

# === 5Ô∏è‚É£ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ===
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y if len(np.unique(y)) > 1 else None
)

# === 6Ô∏è‚É£ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∞–Ω—Ç–∏-–æ–≤–µ—Ä—Ñ–∏—Ç–æ–º ===
print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ RandomForestClassifier (anti-overfitting)...")
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=6,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42
)
model.fit(X_train, y_train)

# === 7Ô∏è‚É£ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è ===
cv_scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"\nüß† –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å (5-Fold CV): {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")

# === 8Ô∏è‚É£ –û—Ü–µ–Ω–∫–∞ ===
y_pred = model.predict(X_test)
report = classification_report(y_test, y_pred, digits=3)
print("\nüìä Classification Report:\n", report)

# === 9Ô∏è‚É£ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
importances = pd.Series(model.feature_importances_, index=feature_columns).sort_values(ascending=False)
print("\nüåå –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n", importances)

# === üîü –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
joblib.dump(model, "rf_model.pkl")
print("\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'rf_model.pkl'")
